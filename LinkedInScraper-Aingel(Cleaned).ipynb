{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pyhunter import PyHunter\n",
    "import pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hunter =PyHunter('26efc74b0216d1530baa4d7ae3aa69c1b843b804')\n",
    "gc = pygsheets.authorize(service_file='AccathonDataBase-8d64c56e6f04.json')\n",
    "sh = gc.open(' ver. Final Accathon capital - High Potential Opportunities ') \n",
    "\n",
    "application = sh.worksheet_by_title('Test_output_aingel output')\n",
    "application= application.get_as_df(has_header=True)\n",
    "table=application\n",
    "\n",
    "#print(table)\n",
    "#table['Company']\n",
    "#print(table)\n",
    "\n",
    "#names=table['Company']\n",
    "#URL=table['LinkedIn']\n",
    "names=table['Company']\n",
    "URL=table['LinkedIn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = requests.Session()\n",
    "HOMEPAGE_URL = 'https://www.linkedin.com'\n",
    "LOGIN_URL = 'https://www.linkedin.com/uas/login-submit'\n",
    "#LOGIN_URL = 'https://www.linkedin.com/uas/connect/user-signin's\n",
    "html = client.get(HOMEPAGE_URL).content\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "csrf = soup.find(id=\"loginCsrfParam-login\")['value']\n",
    "login_information = {\n",
    "    'session_key':'mik279@nyu.edu',  #mik279@nyu.edu\n",
    "    'session_password':'Press@VCKing729',  \n",
    "    'loginCsrfParam': csrf,\n",
    "}\n",
    "\n",
    "#print(csrf)\n",
    "#\n",
    "LOGIN_URL = 'https://www.linkedin.com/uas/login-submit?loginSubmitSource=GUEST_HOME'\n",
    "#\n",
    "client.post(LOGIN_URL, data=login_information)\n",
    "headers={'Accept-Encoding':'identity'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################### AUTO graphing relationships ############################\n",
    "def search(string,z,position):\n",
    "    df_initial = pd.DataFrame(columns=['Company Name','Person Name','Position','Industry','Past Organizations','Title','Location','Start Date','End Date','Summary','LinkedIn URL'])\n",
    "    if(string==\"\"):\n",
    "        print('LinkedIn Profile unavailable for this VC')\n",
    "        #occupations.append(' ')  # N/A\n",
    "        #summaryofprofile.append(' ') # N/A\n",
    "        #names.append(' ') # N/A\n",
    "    if(string!=''):\n",
    "        #if 'linkedin' in str(linkedIn_COO[z]):\n",
    "        try:\n",
    "            profile_url=client.get(string.lstrip(),headers=headers)\n",
    "            string.lstrip()\n",
    "            body=BeautifulSoup(profile_url.content,'html.parser')\n",
    "            text=body.get_text()\n",
    "            summary_text=body.get_text()\n",
    "            ############################### Searching for Profile Summary #############################################            start_summary= summary_text.find('{\"summary\":\"')\n",
    "            start_summary= summary_text.find('{\"summary\":\"')\n",
    "            end_summary=summary_text.find(',\"industryName\":\"')\n",
    "            temp_summaryofprofile=[]\n",
    "            if(start_summary==-1 or end_summary==-1): #& end_summary==-1\n",
    "                #print(\"No summary available for this VC\",linkedIn_COO[z]) \n",
    "                temp_summaryofprofile.append(' ') #N/A\n",
    "                #temp_summaryofprofile='N/A'\n",
    "                #print(temp_summaryofprofile)\n",
    "            elif(start_summary!=-1 & end_summary!=-1):\n",
    "                if(('\\n\\nPreviously Mamoon worked as a Venture Capital' in summary_text[start_summary+12:end_summary-1])==False):\n",
    "                    temp_summaryofprofile.append(summary_text[start_summary+12:end_summary-1])\n",
    "                else:\n",
    "                    temp_summaryofprofile.append(' ')\n",
    "                #temp_summaryofprofile=summary_text[start_summary+12:end_summary-1]\n",
    "                #print(temp_summaryofprofile)\n",
    "            #summaryofprofile.append(temp_summaryofprofile)  \n",
    "            else:\n",
    "                temp_summaryofprofile.append(' ')\n",
    "            \n",
    "            ############################### Searching for First Name and Last Name ##############################\n",
    "            companyindex=[]\n",
    "            companyName=[]\n",
    "            industries=[]\n",
    "            titles=[]\n",
    "            locations=[]\n",
    "            startdates=[]\n",
    "            enddates=[]\n",
    "            person_names=[]\n",
    "            #for m in re.finditer('\"firstName\":\"',text):\n",
    "            #    end_index=text[m.end():].find('\",')\n",
    "            #    temp_first=text[(m.end()):(m.end()+end_index)]\n",
    "            #    last_index=text[m.end():].find('\"lastName\":\"')\n",
    "            #    end_index2=text[(m.end()+last_index):].find('\",')\n",
    "            #    temp_last=text[(m.end()+last_index+12):m.end()+last_index+end_index2]\n",
    "            #    temp_name=temp_first+' '+temp_last\n",
    "            #    person_names.append(temp_name)\n",
    "            #person_names=[x for x in person_names if x!= 'Huiyu(Joey) Zhang']\n",
    "            #if person_names==[]:\n",
    "            #    person_names.append('NA')\n",
    "            #name_final=max(person_names,key=person_names.count)\n",
    "            \n",
    "            \n",
    "            ################################# Education Information ###########################################\n",
    "            schoolindex=[]\n",
    "            schoolnames=[]\n",
    "            degreenames=[]\n",
    "            majors=[]\n",
    "            school_startyears=[]\n",
    "            for m in re.finditer('\"schoolName\":\"',text):\n",
    "                schoolindex.append(m.end())\n",
    "                end_index=text[m.end():].find('\",')\n",
    "                temp_school=text[m.end():(m.end()+end_index)]\n",
    "                schoolnames.append(temp_school)\n",
    "            schoolnames=','.join(list(set(schoolnames)))\n",
    "\n",
    "            for m in re.finditer('\"degreeName\":\"',text):\n",
    "                end_index=text[m.end():].find('\",')\n",
    "                temp_degree=text[m.end():(m.end()+end_index)]\n",
    "                degreenames.append(temp_degree)\n",
    "            degreenames=','.join(list(set(degreenames)))\n",
    "\n",
    "            for m in re.finditer('\"fieldOfStudy\":\"',text):\n",
    "                end_index=text[m.end():].find('\"')\n",
    "                temp_degree=text[m.end():(m.end()+end_index)]\n",
    "                majors.append(temp_degree)\n",
    "            majors=','.join(list(set(majors)))\n",
    "\n",
    "            for i in schoolindex:\n",
    "                temp_text=text[(i-300):i]\n",
    "                if(temp_text.find('\"startDate\":{\"year\":')!=-1):\n",
    "                    startdate_start=temp_text.find('\"startDate\":{\"year\":')\n",
    "                    school_startyears.append(temp_text[(startdate_start+20):(startdate_start+24)])\n",
    "            school_startyears=list(map(int,school_startyears))\n",
    "            if(len(school_startyears)!=0):\n",
    "                min_startyear=min(school_startyears)\n",
    "                roughage=(2018-min_startyear)+18\n",
    "            else:\n",
    "                roughage='NA'\n",
    "                    \n",
    "            ############################## Searching for Past Organizations ################################\n",
    "            for m in re.finditer('\"companyName\":\"',text):\n",
    "                companyindex.append(m.end())\n",
    "                temp_text=text[m.end():]\n",
    "                second_index=m.end()+temp_text.find('\",\"timePeriod\"')\n",
    "                companyName.append(text[m.end():second_index])\n",
    "            companyindex.append(len(text))\n",
    "\n",
    "            for i in range(0,(len(companyindex)-1)):\n",
    "                temp_text=text[companyindex[i]:companyindex[i+1]]\n",
    "                ############# Industry ###############\n",
    "                if(temp_text.find('\"industries\":[\"')==-1):\n",
    "                    industries.append('NA')\n",
    "                else:\n",
    "                    startindex=temp_text.find('\"industries\":[\"')\n",
    "                    endindex=temp_text[startindex:].find('\"],')\n",
    "                    temp_industry=temp_text[startindex+15:(startindex+endindex)]\n",
    "                    industries.append(temp_industry)\n",
    "                ############### title ##################    \n",
    "                if(temp_text.find('\"title\":\"')==-1):\n",
    "                    titles.append('NA')\n",
    "                else:\n",
    "                    startindex=temp_text.find('\"title\":\"')\n",
    "                    endindex=temp_text[startindex:].find('\",')\n",
    "                    temp_title=temp_text[startindex+9:(startindex+endindex)]\n",
    "                    titles.append(temp_title)\n",
    "                ################ location #################\n",
    "                if(temp_text.find('\"locationName\":\"')==-1):\n",
    "                    locations.append('NA')\n",
    "                else:\n",
    "                    startindex=temp_text.find('\"locationName\":\"')\n",
    "                    endindex=temp_text[startindex:].find('\",')\n",
    "                    temp_location=temp_text[startindex+16:(startindex+endindex)]\n",
    "                    locations.append(temp_location)\n",
    "                ################ timeperiod #################\n",
    "                #if(temp_text.find('\"startDate\":{\"month\":')==-1):\n",
    "                #    startdates.append('NA')\n",
    "                #    enddates.append('NA')\n",
    "                #    startindex=temp_text.find()\n",
    "                #else:\n",
    "                #    startindex=temp_text.find('\"startDate\":{\"month\":')\n",
    "                #    endindex=temp_text[startindex:].find(',\"')\n",
    "                #    temp_month=temp_text[startindex+21:(startindex+endindex)]\n",
    "                #    temp_year=temp_text[(startindex+endindex+8):(startindex+endindex+12)]\n",
    "                #    startdates.append(temp_month+'/'+temp_year)\n",
    "                #    if(temp_text[:startindex].find('endDate\":{\"month\":')==-1):\n",
    "                #        enddates.append('NA')\n",
    "                #    elif(temp_text[:startindex].find('endDate\":{\"month\":')!=-1):\n",
    "                #        temptemp_text=temp_text[:startindex]\n",
    "                #        index1=temptemp_text.find('\"endDate\":{\"month\":')\n",
    "                #        index2=temptemp_text[index1:].find(',\"')\n",
    "                #        temp_month2=temptemp_text[(index1+19):(index1+index2)]\n",
    "                #        temp_year2=temptemp_text[(index1+index2+8):(index1+index2+12)]\n",
    "                #        enddates.append(temp_month2+'/'+temp_year2)   \n",
    "\n",
    "                \n",
    "                ################ timeperiod #################\n",
    "                if(temp_text.find('\"endDate\":{\"month\":')==-1):\n",
    "                    #startdates.append('NA')\n",
    "                    #enddates.append('NA')\n",
    "                    if(temp_text.find('\"endDate\":{\"year\":')!=-1):\n",
    "                        startindex=temp_text.find('\"endDate\":{\"year\":')\n",
    "                        endindex=temp_text[startindex:].find(',\"')\n",
    "                        temp_year=temp_text[(startindex+18):(startindex+endindex)]\n",
    "                        enddates.append(temp_year)\n",
    "                        timeperiodindex=temp_text[startindex:].find('\"timePeriod\":')\n",
    "                        if(timeperiodindex==-1):\n",
    "                            if(temp_text.find('\"startDate\":{\"month\":')!=-1):\n",
    "                                startindex1=temp_text.find('\"startDate\":{\"month\":')\n",
    "                                endindex1=temp_text[startindex1:].find(',\"')\n",
    "                                temp_month=temp_text[(startindex1+21):(startindex1+endindex1)]\n",
    "                                temp_year=temp_text[(startindex1+endindex1+8):(startindex1+endindex1+12)]\n",
    "                                startdates.append(temp_month+'/'+temp_year)\n",
    "                            else:\n",
    "                                startindex2=temp_text.find('\"startDate\":{\"year\":')\n",
    "                                endindex2=temp_text[startindex2:].find(',\"')\n",
    "                                temp_year=temp_text[(startindex2+20):(startindex2+endindex2)]\n",
    "                                startdates.append(temp_year)  \n",
    "                        else:\n",
    "                            temptemp_text=temp_text[startindex:(startindex+timeperiodindex)]\n",
    "                            if(temptemp_text.find('\"startDate\":{\"month\":')!=-1):\n",
    "                                startindex1=temptemp_text.find('\"startDate\":{\"month\":')\n",
    "                                endindex1=temptemp_text[startindex1:].find(',\"')\n",
    "                                temp_month=temptemp_text[(startindex1+21):(startindex1+endindex1)]\n",
    "                                temp_year=temptemp_text[(startindex1+endindex1+8):(startindex1+endindex1+12)]\n",
    "                                if(len(temp_month+'/'+temp_year)<=7):\n",
    "                                    startdates.append(temp_month+'/'+temp_year)\n",
    "                                else:\n",
    "                                    startdates.append('NA')\n",
    "                            else:\n",
    "                                startindex2=temptemp_text.find('\"startDate\":{\"year\":')\n",
    "                                endindex2=temptemp_text[startindex2:].find(',\"')\n",
    "                                temp_year=temptemp_text[(startindex2+20):(startindex2+endindex2)]\n",
    "                                if(len(temp_year)==4):\n",
    "                                    startdates.append(temp_year) \n",
    "                                else:\n",
    "                                    startdates.append('NA')\n",
    "                            \n",
    "                    elif(temp_text.find('\"endDate\":{\"year\":')==-1):\n",
    "                        enddates.append('NA')\n",
    "                        if(temp_text.find('\"startDate\":{\"month\":')!=-1):\n",
    "                            startindex=temp_text.find('\"startDate\":{\"month\":')\n",
    "                            endindex=temp_text[startindex:].find(',\"')\n",
    "                            temp_month=temp_text[(startindex+21):(startindex+endindex)]\n",
    "                            temp_year=temp_text[(startindex+endindex+8):(startindex+endindex+12)]\n",
    "                            if(len(temp_month+'/'+temp_year)<=7):\n",
    "                                startdates.append(temp_month+'/'+temp_year)\n",
    "                            else:\n",
    "                                print(table['Company'][z]+'temp_month='+temp_month+',temp_year='+temp_year)\n",
    "                                startdates.append('NA')\n",
    "                        else:\n",
    "                            startindex=temp_text.find('\"startDate\":{\"year\":')\n",
    "                            endindex=temp_text[startindex:].find(',\"')\n",
    "                            temp_year=temp_text[(startindex+20):(startindex+endindex)]\n",
    "                            if(len(temp_year)==4):\n",
    "                                startdates.append(temp_year)\n",
    "                            else:\n",
    "                                startdates.append('NA')\n",
    "                else:\n",
    "                    if(temp_text.find('\"startDate\":{\"month\":')!=-1):\n",
    "                        startindex=temp_text.find('\"startDate\":{\"month\":')\n",
    "                        endindex=temp_text[startindex:].find(',\"')\n",
    "                        temp_month=temp_text[startindex+21:(startindex+endindex)]\n",
    "                        temp_year=temp_text[(startindex+endindex+8):(startindex+endindex+12)]\n",
    "                        startdates.append(temp_month+'/'+temp_year)\n",
    "                        if(temp_text[:startindex].find('endDate\":{\"month\":')==-1):\n",
    "                            enddates.append('NA')\n",
    "                        elif(temp_text[:startindex].find('endDate\":{\"month\":')!=-1):\n",
    "                            temptemp_text=temp_text[:startindex]\n",
    "                            index1=temptemp_text.find('\"endDate\":{\"month\":')\n",
    "                            index2=temptemp_text[index1:].find(',\"')\n",
    "                            temp_month2=temptemp_text[(index1+19):(index1+index2)]\n",
    "                            temp_year2=temptemp_text[(index1+index2+8):(index1+index2+12)]\n",
    "                            enddates.append(temp_month2+'/'+temp_year2)\n",
    "                    else:\n",
    "                        startindex=temp_text.find('\"startDate\":{\"year\":')\n",
    "                        endindex=temp_text[startindex:].find(',\"')\n",
    "                        temp_year=temp_text[(startindex+20):(startindex+endindex)]\n",
    "                        startdates.append(temp_year)\n",
    "                        if(temp_text[:startindex].find('endDate\":{\"month\":')==-1):\n",
    "                            enddates.append('NA')\n",
    "                            temptemp_text=temp_text[:startindex]\n",
    "                            index1=temptemp_text.find('\"endDate\":{\"month\":')\n",
    "                            index2=temptemp_text[index1:].find(',\"')\n",
    "                            temp_month2=temptemp_text[(index1+19):(index1+index2)]\n",
    "                            temp_year2=temptemp_text[(index1+index2+8):(index1+index2+12)]\n",
    "                            enddates.append(temp_month2+'/'+temp_year2)\n",
    "                                     \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "            df_person=pd.DataFrame({\n",
    "                'Company Name':[table['Company'][z]]*(len(companyName)),\n",
    "                #'Person Name':[name_final]*(len(companyName)),\n",
    "                'Person Name':[table['Name'][z]]*(len(companyName)),\n",
    "                'Position':[position]*(len(companyName)),\n",
    "                'Industry':industries,\n",
    "                'Past Organizations':companyName,\n",
    "                'Title':titles,\n",
    "                'Location':locations,\n",
    "                'Start Date': startdates,\n",
    "                'End Date':enddates,\n",
    "                'Summary':temp_summaryofprofile*(len(companyName)),\n",
    "                'School Names':[schoolnames]*(len(companyindex)-1),\n",
    "                'Degrees':[degreenames]*(len(companyindex)-1),\n",
    "                'Majors':[majors]*(len(companyindex)-1),\n",
    "                'Rough Age':[roughage]*(len(companyindex)-1),\n",
    "                'LinkedIn URL':[string]*(len(companyName))\n",
    "                })\n",
    "            df_initial=pd.concat([df_initial,df_person])\n",
    "            #print(temp_summaryofprofile)          \n",
    "        except:\n",
    "            #print(temp_summaryofprofile)\n",
    "            print('Unsuccessful scraping for '+table['Company'][z])\n",
    "            #print(len(startdates))\n",
    "            #print(len(enddates))\n",
    "            #print(len(companyName))\n",
    "    return(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Degrees</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Industry</th>\n",
       "      <th>LinkedIn URL</th>\n",
       "      <th>Location</th>\n",
       "      <th>Majors</th>\n",
       "      <th>Past Organizations</th>\n",
       "      <th>Person Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Rough Age</th>\n",
       "      <th>School Names</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company Name, Degrees, End Date, Industry, LinkedIn URL, Location, Majors, Past Organizations, Person Name, Position, Rough Age, School Names, Start Date, Summary, Title]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_start=2000     #2730-2735    # 5258-5263  # 674-675 # 1687-1694\n",
    "sample_end=2010\n",
    "df= pd.DataFrame(columns=['Company Name','Person Name','Position','Industry','Past Organizations','Title','Location',\n",
    "                          'Start Date','End Date','Summary','School Names','Degrees','Majors','Rough Age','LinkedIn URL'])\n",
    "for i in range(sample_start,sample_end):  #len(linkedIn_COO) #len(URL)\n",
    "    Founder=search(URL[i],i,'Founder or Investor')\n",
    "    #CTO=search(linkedIn_CTO[i],i,'CTO')\n",
    "    #COO=search(linkedIn_COO[i],i,'COO')\n",
    "    #newdf=pd.concat([CEO,CTO,COO])  \n",
    "    #df=pd.concat([df,newdf])\n",
    "    df=pd.concat([df,Founder])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authorization\n",
    "gc = pygsheets.authorize(service_file='AccathonDataBase-8d64c56e6f04.json')\n",
    "sh=gc.open('Startup Evaluation')\n",
    "relationship=sh.worksheet_by_title('Raw')\n",
    "#relationship.set_dataframe(df,start=\"A1\")\n",
    "relationship= relationship.get_as_df(has_header=True)\n",
    "#print(len(relationship)+2)\n",
    "newstart='A'+ str(len(relationship)+2)\n",
    "#relationship.set_dataframe(df,start=newstart)\n",
    "sh.worksheet_by_title('Raw').set_dataframe(df,start=newstart,copy_head=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
